{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import platform\n",
    "import os\n",
    "from sklearn import datasets\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, roc_curve, auc\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_direc = os.getcwd() + \"/\"\n",
    "if platform.system() == \"Windows\":\n",
    "    data_direc = data_direc.replace(\"/\", \"\\\\\")\n",
    "train = pd.read_csv(data_direc + \"arcene_train.csv\",header = None)\n",
    "true_train_labels = pd.read_csv(data_direc + \"arcene_train_labels.csv\")\n",
    "test = pd.read_csv(data_direc + \"arcene_valid.csv\",header = None)\n",
    "test_labels = pd.read_csv(data_direc + \"arcene_valid_labels.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_function(y, pred):\n",
    "    y = 2 * y - 1\n",
    "    return np.sum(np.log(1 + np.exp(-y * pred)))\n",
    "\n",
    "# Normalize the data\n",
    "scaler = StandardScaler()\n",
    "train_normalized = scaler.fit_transform(train)\n",
    "test_normalized = scaler.transform(test)\n",
    "\n",
    "# Define parameters\n",
    "s = 0.001\n",
    "mu = 300 \n",
    "N_iter = 300\n",
    "k_values = [600]\n",
    "class_probabilities = np.zeros(len(true_train_labels)).reshape(-1, 1)\n",
    "\n",
    "# Initialize lists to store results\n",
    "train_losses = []\n",
    "test_losses = []\n",
    "train_errors = []\n",
    "test_errors = []\n",
    "\n",
    "train_labels = (true_train_labels + 1) / 2\n",
    "\n",
    "for k in k_values:\n",
    "    train_losses_iter = []\n",
    "    for _ in range(k):\n",
    "        best_loss = float('inf')\n",
    "        best_predictor = None\n",
    "        for feature_idx in range(train.shape[1]):\n",
    "            # Fit univariate linear regressor\n",
    "            X_feature = np.array(train.iloc[:, feature_idx]).reshape(-1, 1)\n",
    "            exp_term = -1*np.array(class_probabilities)\n",
    "            exp_term = np.clip(exp_term, -500, 500)  # Limit the range of the exponent to prevent overflow\n",
    "            p = np.ones(len(train_labels)).reshape(-1,1) / (np.ones(len(train_labels)).reshape(-1,1) + np.exp(exp_term))\n",
    "            w = p*(np.ones(len(train_labels)).reshape(-1,1) - p)\n",
    "            # Handle division by zero or close to zero values in w\n",
    "            w_mask = np.isclose(w, 0)\n",
    "            w[w_mask] = 1  # Replace zero or close to zero values with 1\n",
    "            \n",
    "            z = np.zeros_like(train_labels)  # Initialize z array\n",
    "            z[~w_mask] = ((np.array(train_labels)[~w_mask]) - p[~w_mask]) / w[~w_mask]\n",
    "            \n",
    "            temp_x = X_feature * w.reshape(-1, 1)  # Reshape w to match the shape of X_feature\n",
    "            lr = LinearRegression().fit(temp_x, z)\n",
    "            pred = lr.predict(X_feature)\n",
    "\n",
    "            # Calculate loss\n",
    "            loss = loss_function(train_labels, pred)\n",
    "            if loss.iloc[0] < best_loss:\n",
    "                print(\"better :)\")\n",
    "                best_loss = loss.iloc[0]\n",
    "                best_predictor = lr\n",
    "\n",
    "        train_losses_iter.append(loss_function(train_labels, class_probabilities))  # Append the training loss at each iteration\n",
    "        # Update class probabilities\n",
    "        class_probabilities += best_predictor.predict(X_feature).reshape(-1, 1)\n",
    "\n",
    "    train_losses.append(train_losses_iter)\n",
    "    # Calculate training and test loss\n",
    "    train_loss = loss_function(train_labels, class_probabilities)\n",
    "    test_loss = loss_function(test_labels, class_probabilities)\n",
    "\n",
    "    # Calculate training and test error\n",
    "    train_pred = np.sign(class_probabilities)\n",
    "    test_pred = np.sign(class_probabilities)\n",
    "    train_error = 1 - accuracy_score(train_labels, train_pred)\n",
    "    test_error = 1 - accuracy_score(test_labels, test_pred)\n",
    "        \n",
    "    train_losses.append(train_losses_iter)  # Append the list of training losses for this k to train_losses\n",
    "\n",
    "    test_losses.append(test_loss)\n",
    "    train_errors.append(train_error)\n",
    "    test_errors.append(test_error)\n",
    "    print(f\"{k} done\")\n",
    "\n",
    "# Plot training loss vs iteration number for k = 600\n",
    "plt.plot(range(1, 601), train_losses[-1])\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('Training Loss')\n",
    "plt.title('Training Loss vs Iteration Number for k = 600')\n",
    "plt.show()\n",
    "\n",
    "# Report misclassification errors on the training and test sets for all values of k\n",
    "error_table = pd.DataFrame({'k': k_values, 'Train Error': train_errors, 'Test Error': test_errors})\n",
    "print(error_table)\n",
    "\n",
    "# Plot misclassification errors on the training and test sets vs k\n",
    "plt.plot(k_values, train_errors, label='Train Error')\n",
    "plt.plot(k_values, test_errors, label='Test Error')\n",
    "plt.xlabel('Number of Boosting Iterations (k)')\n",
    "plt.ylabel('Misclassification Error')\n",
    "plt.title('Misclassification Error vs Number of Boosting Iterations')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_direc = os.getcwd() + \"/\"\n",
    "if platform.system() == \"Windows\":\n",
    "    data_direc = data_direc.replace(\"/\", \"\\\\\")\n",
    "train = pd.read_csv(data_direc + \"gisette_train.csv\")\n",
    "train_labels = pd.read_csv(data_direc + \"gisette_train_labels.csv\")\n",
    "test = pd.read_csv(data_direc + \"gisette_valid.csv\")\n",
    "test_labels = pd.read_csv(data_direc + \"gisette_valid_labels.csv\")\n",
    "train = np.delete(train, 5000, axis=1)\n",
    "test = np.delete(test, 5000, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_function(y, pred):\n",
    "    return np.log(1 + np.exp(-2 * y * pred)).mean()\n",
    "\n",
    "# Normalize the data\n",
    "scaler = StandardScaler()\n",
    "train_normalized = scaler.fit_transform(train)\n",
    "test_normalized = scaler.transform(test)\n",
    "\n",
    "# Define parameters\n",
    "s = 0.001\n",
    "mu = 300 \n",
    "N_iter = 300\n",
    "k_values = [600]\n",
    "class_probabilities = np.zeros(len(true_train_labels)).reshape(-1, 1)\n",
    "\n",
    "# Initialize lists to store results\n",
    "train_losses = []\n",
    "test_losses = []\n",
    "train_errors = []\n",
    "test_errors = []\n",
    "\n",
    "train_labels = (true_train_labels + 1) / 2\n",
    "\n",
    "for k in k_values:\n",
    "    train_losses_iter = []\n",
    "    for _ in range(k):\n",
    "        best_loss = float('inf')\n",
    "        best_predictor = None\n",
    "        for feature_idx in range(train.shape[1]):\n",
    "            # Fit univariate linear regressor\n",
    "            X_feature = np.array(train.iloc[:, feature_idx]).reshape(-1, 1)\n",
    "            exp_term = -1*np.array(class_probabilities)\n",
    "            exp_term = np.clip(exp_term, -500, 500)  # Limit the range of the exponent to prevent overflow\n",
    "            p = np.ones(len(train_labels)).reshape(-1,1) / (np.ones(len(train_labels)).reshape(-1,1) + np.exp(exp_term))\n",
    "            print((np.ones(len(train_labels)).reshape(-1,1) + np.exp(exp_term)))\n",
    "            w = p*(np.ones(len(train_labels)).reshape(-1,1) - p)\n",
    "            # Handle division by zero or close to zero values in w\n",
    "            w_mask = np.isclose(w, 0)\n",
    "            w[w_mask] = 1  # Replace zero or close to zero values with 1\n",
    "            \n",
    "            z = np.zeros_like(train_labels)  # Initialize z array\n",
    "            z[~w_mask] = ((np.array(train_labels)[~w_mask]) - p[~w_mask]) / w[~w_mask]\n",
    "            \n",
    "            temp_x = X_feature * w.reshape(-1, 1)  # Reshape w to match the shape of X_feature\n",
    "            lr = LinearRegression().fit(temp_x, z)\n",
    "            pred = lr.predict(X_feature)\n",
    "\n",
    "            # Calculate loss\n",
    "            loss = loss_function(train_labels, pred)\n",
    "            if loss.iloc[0] < best_loss:\n",
    "                best_loss = loss.iloc[0]\n",
    "                best_predictor = lr\n",
    "            \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        train_losses_iter.append(loss_function(train_labels, class_probabilities))  # Append the training loss at each iteration\n",
    "        # Update class probabilities\n",
    "        class_probabilities += best_predictor.predict(X_feature)\n",
    "\n",
    "    train_losses.append(train_losses_iter)\n",
    "    # Calculate training and test loss\n",
    "    train_loss = loss_function(train_labels, class_probabilities)\n",
    "    test_loss = loss_function(test_labels, class_probabilities)\n",
    "\n",
    "    # Calculate training and test error\n",
    "    train_pred = np.where(class_probabilities >= 0, 1, 0)\n",
    "    test_pred = np.where(class_probabilities >= 0, 1, 0)\n",
    "    train_error = 1 - accuracy_score(train_labels, train_pred)\n",
    "    test_error = 1 - accuracy_score(test_labels, test_pred)\n",
    "        \n",
    "    train_losses.append(train_losses_iter)  # Append the list of training losses for this k to train_losses\n",
    "\n",
    "    test_losses.append(test_loss)\n",
    "    train_errors.append(train_error)\n",
    "    test_errors.append(test_error)\n",
    "    print(f\"{k} done\")\n",
    "\n",
    "# Plot training loss vs iteration number for k = 600\n",
    "plt.plot(range(1, 601), train_losses[-1])\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('Training Loss')\n",
    "plt.title('Training Loss vs Iteration Number for k = 600')\n",
    "plt.show()\n",
    "\n",
    "# Report misclassification errors on the training and test sets for all values of k\n",
    "error_table = pd.DataFrame({'k': k_values, 'Train Error': train_errors, 'Test Error': test_errors})\n",
    "print(error_table)\n",
    "\n",
    "# Plot misclassification errors on the training and test sets vs k\n",
    "plt.plot(k_values, train_errors, label='Train Error')\n",
    "plt.plot(k_values, test_errors, label='Test Error')\n",
    "plt.xlabel('Number of Boosting Iterations (k)')\n",
    "plt.ylabel('Misclassification Error')\n",
    "plt.title('Misclassification Error vs Number of Boosting Iterations')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 1)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_probabilities.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_direc = os.getcwd() + \"/\"\n",
    "if platform.system() == \"Windows\":\n",
    "    data_direc = data_direc.replace(\"/\", \"\\\\\")\n",
    "train = pd.read_csv(data_direc + \"gisette_train.csv\")\n",
    "train_labels = pd.read_csv(data_direc + \"gisette_train_labels.csv\")\n",
    "test = pd.read_csv(data_direc + \"gisette_valid.csv\")\n",
    "test_labels = pd.read_csv(data_direc + \"gisette_valid_labels.csv\")\n",
    "train = np.delete(train, 5000, axis=1)\n",
    "test = np.delete(test, 5000, axis=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data_analysis",
   "language": "python",
   "name": "data_analysis"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
