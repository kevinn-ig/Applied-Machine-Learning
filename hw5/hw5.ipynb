{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 5\n",
    "Evelina Teran & Kevin Smith"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import platform\n",
    "import os\n",
    "from sklearn import datasets\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, roc_curve, auc\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lorenz Loss:\n",
    "# if(x >1): 0\n",
    "# else: ln(1+(x-1)**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_direc = os.getcwd() + \"/\"\n",
    "if platform.system() == \"Windows\":\n",
    "    data_direc = data_direc.replace(\"/\", \"\\\\\")\n",
    "train = pd.read_csv(data_direc + \"gisette_train.csv\")\n",
    "train_labels = pd.read_csv(data_direc + \"gisette_train_labels.csv\")\n",
    "test = pd.read_csv(data_direc + \"gisette_valid.csv\")\n",
    "test_labels = pd.read_csv(data_direc + \"gisette_valid_labels.csv\")\n",
    "train = np.delete(train, 5000, axis=1)\n",
    "test = np.delete(test, 5000, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the data\n",
    "scaler = StandardScaler()\n",
    "train_normalized = scaler.fit_transform(train)\n",
    "test_normalized = scaler.transform(test)\n",
    "\n",
    "# Define parameters\n",
    "s = 0.001\n",
    "mu = 300\n",
    "N_iter = 300\n",
    "\n",
    "# Define k values\n",
    "k_values = [10, 30, 100, 300, 500]\n",
    "\n",
    "# Initialize beta, gamma, and selected variables\n",
    "beta = np.zeros(train_normalized.shape[1])\n",
    "gamma = np.zeros(train_normalized.shape[1])\n",
    "selected_vars = []\n",
    "\n",
    "# FSA algorithm with modification to record the loss\n",
    "losses_k100 = []  # To store the training loss for k=100\n",
    "for _ in range(N_iter):\n",
    "    loss = 0  # Initialize loss for this iteration\n",
    "    for j in range(train_normalized.shape[1]):\n",
    "        gamma_j = gamma[j] + mu * beta[j]\n",
    "        beta_j = beta.copy()\n",
    "        beta_j[j] = 0\n",
    "        z = np.dot(train_normalized, beta_j)\n",
    "        yz = np.multiply(train_labels.values.flatten(), z)\n",
    "        l_prime = np.where(yz > 1, 0, -2 * (yz - 1) / (1 + (yz - 1) ** 2))\n",
    "        gradient_j = np.mean(np.multiply(l_prime, train_normalized[:, j])) + 2 * s * beta[j]\n",
    "        gamma[j] = gamma_j - mu * gradient_j\n",
    "        beta[j] = np.sign(gamma[j]) * max(0, abs(gamma[j]) - mu * s)\n",
    "        if (yz <= 1).all():\n",
    "            loss += np.log(1 + (yz - 1) ** 2)\n",
    "    \n",
    "    losses_k100.append(loss / len(train_normalized))\n",
    "\n",
    "# Plot training loss vs iteration number for k=100\n",
    "plt.plot(losses_k100)\n",
    "plt.xlabel('Iteration number')\n",
    "plt.ylabel('Training loss')\n",
    "plt.title('Training loss vs iteration number for k=100')\n",
    "plt.show()\n",
    "\n",
    "# Initialize lists to store results\n",
    "train_errors = []\n",
    "test_errors = []\n",
    "roc_aucs = []\n",
    "\n",
    "# Plot misclassification error vs k\n",
    "plt.plot(k_values, train_errors, label='Training error')\n",
    "plt.plot(k_values, test_errors, label='Test error')\n",
    "plt.xlabel('Number of features (k)')\n",
    "plt.ylabel('Misclassification error')\n",
    "plt.title('Misclassification error vs k')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Define k value for ROC curve\n",
    "k_roc = 100\n",
    "\n",
    "# Select the top k features based on the FSA algorithm for ROC curve\n",
    "selected_vars_k100 = np.argsort(np.abs(gamma))[-k_roc:]\n",
    "train_selected_k100 = train[:, selected_vars_k100]\n",
    "test_selected_k100 = test[:, selected_vars_k100]\n",
    "\n",
    "# Use the existing logistic regression model with k=100 features for predictions\n",
    "train_pred_prob_k100 = np.dot(train_selected_k100, beta)\n",
    "test_pred_prob_k100 = np.dot(test_selected_k100, beta)\n",
    "\n",
    "# Calculate the false positive rate (fpr) and true positive rate (tpr) for the ROC curve\n",
    "fpr_k100, tpr_k100, _ = roc_curve(test_labels, test_pred_prob_k100)\n",
    "\n",
    "# Calculate the ROC AUC score\n",
    "roc_auc_k100 = auc(fpr_k100, tpr_k100)\n",
    "\n",
    "# Plot ROC curve for k=100\n",
    "plt.figure()\n",
    "plt.plot(fpr_k100, tpr_k100, label='ROC curve (area = %0.2f)' % roc_auc_k100)\n",
    "plt.plot([0, 1], [0, 1], linestyle='--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve for k=100')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assume train and test data are already defined\n",
    "scaler = StandardScaler()\n",
    "train = scaler.fit_transform(train)\n",
    "test = scaler.transform(test)\n",
    "\n",
    "# Define k values\n",
    "k_values = [10, 30, 100, 300, 500]\n",
    "\n",
    "# Perform FSA\n",
    "train_errors, test_errors, train_roc_auc, test_roc_auc, fpr_train, tpr_train, fpr_test, tpr_test = fsa(train, train_labels, test, test_labels, k_values)\n",
    "\n",
    "# Plot ROC curves\n",
    "num_features_values = [10, 30, 100, 300, 500]\n",
    "fig, axs = plt.subplots(2, 3, figsize=(15, 10))\n",
    "\n",
    "for i, num_features in enumerate(num_features_values):\n",
    "    ax = axs[i // 3, i % 3]\n",
    "    ax.plot(fpr_train[i], tpr_train[i], label=\"Training ROC Curve (AUC = {:.2f})\".format(train_roc_auc[i]))\n",
    "    ax.plot(fpr_test[i], tpr_test[i], label=\"Test ROC Curve (AUC = {:.2f})\".format(test_roc_auc[i]))\n",
    "    ax.plot([0, 1], [0, 1], color=\"navy\", lw=2, linestyle=\"--\")\n",
    "    ax.set_xlabel(\"False Positive Rate\")\n",
    "    ax.set_ylabel(\"True Positive Rate\")\n",
    "    ax.set_title(f\"ROC Curve for {num_features} features\")\n",
    "    ax.legend(loc=\"lower right\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(data_direc + \"dexter_train.csv\", header = None)\n",
    "train_labels = pd.read_csv(data_direc + \"dexter_train_labels.csv\", header = None)\n",
    "test = pd.read_csv(data_direc + \"dexter_valid.csv\", header = None)\n",
    "test_labels = pd.read_csv(data_direc + \"dexter_valid_labels.csv\", header = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "train = scaler.fit_transform(train)\n",
    "test = scaler.transform(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_fwf(data_direc + \"madelon_train.data\", header = None)\n",
    "train_labels = pd.read_fwf(data_direc + \"madelon_train.labels\", header = None)\n",
    "test = pd.read_fwf(data_direc + \"madelon_valid.data\", header = None)\n",
    "test_labels = pd.read_fwf(data_direc + \"madelon_valid.labels\", header = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "train = scaler.fit_transform(train)\n",
    "test = scaler.transform(test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
